{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## R8\n",
    "<font color=\"blue\">R8数据集介绍:</font>\n",
    "The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "Class | train docs\t| test docs\t| Total docs\n",
    "-----|------|------|-----|------\n",
    "acq\t|1596 |\t696\t| 2292\n",
    "crude |\t253\t| 121\t| 374\n",
    "earn |\t2840 | 1083 | 3923\n",
    "grain |\t41 | 10 | 51\n",
    "interest |\t190\t| 81 | 271\n",
    "money-fx |\t206\t| 87 | 293\n",
    "ship | 108\t| 36\t| 144\n",
    "trade |\t251\t| 75\t| 326\n",
    "Total |\t5485 | 2189\t| 7674\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伪代码：\n",
    "```python\n",
    "每一个类别维护一个大的词汇表;\n",
    "在整篇训练集文档，按行遍历:\n",
    "    对于每一个类别(每一行开头标识):\n",
    "        如果当前行词条在该行中出现（每一行相当于一个文档，重复出现的也只计数一次）-->增加该词条的计数\n",
    "        增加该类别词汇表的总计数\n",
    "    对于每一个类别：\n",
    "        对于每一个词条：\n",
    "            将该词条的数目除以总词条数目得到条件概率\n",
    "    返回每一个类别的条件概率\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: split() requires a non-empty pattern match.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "#加载数据，参数是训练集路径\n",
    "def loadDataSet(filepath):\n",
    "    return (open(filepath).read())\n",
    "#创建不重复词的列表,参数是整片训练集\n",
    "def createVocabList(dadaSet):\n",
    "    import re\n",
    "    #切割单词\n",
    "    regEx=re.compile('\\\\W*')\n",
    "    vocabSet=set(regEx.split(dataSet))\n",
    "    return list(vocabSet)\n",
    "\n",
    "#统计，输入词汇表，输入文档路径\n",
    "def setOfWords2Vec(vocabList,filepath):\n",
    "    import re\n",
    "    import numpy as np\n",
    "    width=len(vocabList)\n",
    "    height=8\n",
    "    weight=np.ones(height,width)\n",
    "    \n",
    "    catagory={'acq':0,'crude':1,'earn':2,'grain':3,'interest':4,'money':5,'ship':6,'trade':7}\n",
    "\n",
    "    regEx=re.compile('\\\\W*')\n",
    "    with open(filepath,'r',encoding='utf8')as file:\n",
    "        for lines in file:\n",
    "            #中间变量，每一次中间进行置零\n",
    "            value=np.zeros(height,width)\n",
    "            words=regEx.split(lines)\n",
    "            for word in words:\n",
    "                    #保证计数，但是重复不累加\n",
    "                    value[catagory[words[0]]][vocabList.index(word)]=1\n",
    "            #统计，累加，得到频率，方便计算条件概率\n",
    "            weight=weight+value\n",
    "    return weight\n",
    "\n",
    "#朴素贝叶斯分类器训练函数\n",
    "def trainNB():\n",
    "    pass\n",
    "#朴素贝叶斯分类函数\n",
    "def classifyNB():\n",
    "    pass\n",
    "#对模型进行检验\n",
    "def testingNB():\n",
    "    pass\n",
    "if __name__=='__main__':\n",
    "    dataSet=loadDataSet('data/task1/r8-train-stemmed.txt')\n",
    "    cocabList=createVocabList(dataSet)\n",
    "    setOfWords2Vec(cocabList,'data/task1/r8-train-stemmed.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
