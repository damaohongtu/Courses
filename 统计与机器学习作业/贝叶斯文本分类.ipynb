{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## R8\n",
    "<font color=\"blue\">R8数据集介绍:</font>\n",
    "The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "Class | train docs\t| test docs\t| Total docs\n",
    "-----|------|------|-----|------\n",
    "acq\t|1596 |\t696\t| 2292\n",
    "crude |\t253\t| 121\t| 374\n",
    "earn |\t2840 | 1083 | 3923\n",
    "grain |\t41 | 10 | 51\n",
    "interest |\t190\t| 81 | 271\n",
    "money-fx |\t206\t| 87 | 293\n",
    "ship | 108\t| 36\t| 144\n",
    "trade |\t251\t| 75\t| 326\n",
    "Total |\t5485 | 2189\t| 7674\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伪代码：\n",
    "```python\n",
    "每一个类别维护一个大的词汇表;\n",
    "在整篇训练集文档，按行遍历:\n",
    "    对于每一个类别(每一行开头标识):\n",
    "        如果当前行词条在该行中出现（每一行相当于一个文档，重复出现的也只计数一次）-->增加该词条的计数\n",
    "        增加该类别词汇表的总计数\n",
    "    对于每一个类别：\n",
    "        对于每一个词条：\n",
    "            将该词条的数目除以总词条数目得到条件概率\n",
    "    返回每一个类别的条件概率\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: split() requires a non-empty pattern match.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: split() requires a non-empty pattern match.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-7a242aa13416>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdataSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloadDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/task1/r8-train-stemmed.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mcocabList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreateVocabList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetOfWords2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcocabList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'data/task1/r8-train-stemmed.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "#加载数据，参数是训练集路径\n",
    "def loadDataSet(filepath):\n",
    "    return (open(filepath).read())\n",
    "#创建不重复词的列表,参数是整片训练集\n",
    "def createVocabList(dadaSet):\n",
    "    import re\n",
    "    #切割单词\n",
    "    regEx=re.compile('\\\\W*')\n",
    "    vocabSet=set(regEx.split(dataSet))\n",
    "    return list(vocabSet)\n",
    "\n",
    "#统计，输入词汇表，输入文档路径\n",
    "def setOfWords2Vec(vocabList,filepath):\n",
    "    import re\n",
    "    import numpy as np\n",
    "    width=len(vocabList)\n",
    "    height=8\n",
    "    #防止最终乘积为零，初始化的时候全1\n",
    "    weight=np.ones((height,width))\n",
    "    #建立类别字典\n",
    "    catagory={'acq':0,'crude':1,'earn':2,'grain':3,'interest':4,'money':5,'ship':6,'trade':7}\n",
    "\n",
    "    regEx=re.compile('\\\\W*')\n",
    "    with open(filepath,'r',encoding='utf8')as file:\n",
    "        for lines in file:\n",
    "            #中间变量，每一次中间进行置零\n",
    "            value=np.zeros((height,width))\n",
    "            words=regEx.split(lines)\n",
    "            for word in words:\n",
    "                #保证计数，但是重复不累加\n",
    "                value[catagory[words[0]]][vocabList.index(word)]=1\n",
    "            #统计，累加，得到频率，方便计算条件概率\n",
    "            weight=weight+value\n",
    "    return weight\n",
    "\n",
    "#朴素贝叶斯分类器训练函数,输入是统计的频率\n",
    "def trainNB(trainMatrix):\n",
    "    for i in range(trainMatrix.shape[0]):\n",
    "        temp=sum(trainMatrix[i])\n",
    "        for j in range(trainMatrix.shape[1]):\n",
    "            #防止下溢出，求对数\n",
    "            trainMatrix[i][j]=np.log(trainMatrix[i][j]*(1.0)/temp)\n",
    "    return trainMatrix\n",
    "\n",
    "#朴素贝叶斯分类函数\n",
    "def classifyNB():\n",
    "    pass\n",
    "#对模型进行检验\n",
    "def testingNB():\n",
    "    pass\n",
    "if __name__=='__main__':\n",
    "    dataSet=loadDataSet('data/task1/r8-train-stemmed.txt')\n",
    "    cocabList=createVocabList(dataSet)\n",
    "    trainMatrix=setOfWords2Vec(cocabList,'data/task1/r8-train-stemmed.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.ones((3,4))\n",
    "b=np.asarray([8,5,9,6,3,2,4])\n",
    "print(max(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
